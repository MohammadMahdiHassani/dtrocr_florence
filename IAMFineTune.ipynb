{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4cda29000b17cc0a",
      "metadata": {
        "id": "4cda29000b17cc0a"
      },
      "source": [
        "# Fine-tuning DTrOCR on IAM dataset\n",
        "This is an example of fine-tuning DTrOCR on IAM dataset handwritten words from [Kaggle](https://www.kaggle.com/datasets/teykaicong/iamondb-handwriting-dataset). IAM Aachen splits can be downloaded [here](https://www.openslr.org/56/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672df8f4f58440b7",
      "metadata": {
        "id": "672df8f4f58440b7"
      },
      "source": [
        "# Dataset folder structure\n",
        "```\n",
        "iam_words/\n",
        "│\n",
        "├── words/                              # Folder containing word images as PNGs\n",
        "│   ├── a01/                            # First folder\n",
        "│   │   ├── a01-000u/\n",
        "│   │   │   ├── a01-000u-00-00.png\n",
        "│   │   │   └── a01-000u-00-01.png\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   └── r06/                            # Last folder\n",
        "│       ├── r06-000/\n",
        "│       │   ├── r06-000-00-00.png\n",
        "│       │   └── r06-000-00-01.png\n",
        "│\n",
        "├── xml/                                # XML files\n",
        "│\t├── a01-000u.xml\n",
        "│\t.\n",
        "│\t.\n",
        "│\t.\n",
        "│\t└── r06-143.xml\n",
        "│\n",
        "└── splits/                             # IAM Aachen splits\n",
        "    ├── train.uttlist\n",
        "    ├── validation.uttlist\n",
        "    └── test.uttlist\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f83c2b6af325eb",
      "metadata": {
        "id": "89f83c2b6af325eb"
      },
      "source": [
        "# Build lists of images and texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0Tz0PKVm3hNH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tz0PKVm3hNH",
        "outputId": "b81c307c-87d6-44ed-9518-65cd874ca8e7"
      },
      "outputs": [],
      "source": [
        "#!pip install triton==2.0.0 # Install Triton explicitly with a version compatible with PyTorch Inductor.\n",
        "\n",
        "import torch\n",
        "torch.set_float32_matmul_precision('high')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa6ad879545d49c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa6ad879545d49c7",
        "outputId": "08a19f21-1da9-4491-a610-269d1257dde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1539 XML files and 115320 word image files\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_path = Path('iam_words')\n",
        "\n",
        "xml_files = sorted(glob.glob(str(dataset_path / 'xml' / '*.xml')))\n",
        "word_image_files = sorted(glob.glob(str(dataset_path / 'words' / '**' / '*.png'), recursive=True))\n",
        "\n",
        "print(f\"{len(xml_files)} XML files and {len(word_image_files)} word image files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6wC_EzQfhZly",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wC_EzQfhZly",
        "outputId": "32d64c26-9ece-45fa-cb49-0728e5465766"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Define the Word class\n",
        "class Word:\n",
        "    def __init__(self, word_id, file_path, writer_id, transcription):\n",
        "        self.id:str = word_id\n",
        "        self.file_path:Path = file_path\n",
        "        self.writer_id:str = writer_id\n",
        "        self.transcription:str = transcription\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Word(id='{self.id}', file_path=PosixPath('{self.file_path}'), \"\n",
        "                f\"writer_id='{self.writer_id}', transcription='{self.transcription}')\")\n",
        "pattern = r\"Word\\(id='([^']+)',\\s*file_path=PosixPath\\('([^']+)'\\),\\s*writer_id='([^']+)',\\s*transcription='([^']+)'\\)\"\n",
        "\n",
        "def extract_word_obj(line:str):\n",
        "  match = re.search(pattern, line)\n",
        "\n",
        "# Check if the match was successful\n",
        "  if match:\n",
        "    word_id = match.group(1)\n",
        "    file_path = Path(match.group(2))  # Convert the string to a Path object\n",
        "    writer_id = match.group(3)\n",
        "    transcription = match.group(4)\n",
        "\n",
        "    # Create the Word object\n",
        "    word_object = Word(word_id, file_path, writer_id, transcription)\n",
        "    return word_object\n",
        "words = []\n",
        "# Example: Reading the file and loading each line as a Word object\n",
        "file_path = 'words_local.txt'  # Replace with your file path\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    # Read the lines of the file and convert each to a Word instance\n",
        "    for line in file.readlines():\n",
        "      word = extract_word_obj(line)\n",
        "      words.append(word)\n",
        "# Print the loaded Word instan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ea1601f0dabbde",
      "metadata": {
        "id": "d0ea1601f0dabbde"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c5c924f758cc73a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5c924f758cc73a4",
        "outputId": "64177ffd-a560-45c1-f382-18b8d9030296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 747; Validation size: 116; Test size: 336\n"
          ]
        }
      ],
      "source": [
        "with open('iam_words/splits/train.uttlist') as fp:\n",
        "    train_ids = [line.replace('\\n', '') for line in fp.readlines()]\n",
        "\n",
        "with open('iam_words/splits/test.uttlist') as fp:\n",
        "    test_ids = [line.replace('\\n', '') for line in fp.readlines()]\n",
        "\n",
        "with open('iam_words/splits/validation.uttlist') as fp:\n",
        "    validation_ids = [line.replace('\\n', '') for line in fp.readlines()]\n",
        "\n",
        "print(f\"Train size: {len(train_ids)}; Validation size: {len(validation_ids)}; Test size: {len(test_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ddcnEs96lNkY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddcnEs96lNkY",
        "outputId": "46b18ecd-90ba-4a6f-e693-ec976504481c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "113332\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for word in words:\n",
        "  if words[i] == None:\n",
        "    words.pop(i)\n",
        "  i += 1\n",
        "print(len(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b5433445168c7f98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5433445168c7f98",
        "outputId": "07935b35-426a-44b0-e059-c46b4458bab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 54315; Validation size: 8727; Test size: 25491\n"
          ]
        }
      ],
      "source": [
        "train_word_records = [word for word in words if word.id in train_ids]\n",
        "validation_word_records = [word for word in words if word.id in validation_ids]\n",
        "test_word_records = [word for word in words if word.id in test_ids]\n",
        "\n",
        "print(f'Train size: {len(train_word_records)}; Validation size: {len(validation_word_records)}; Test size: {len(test_word_records)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1d6d01cac2ef35",
      "metadata": {
        "id": "ce1d6d01cac2ef35"
      },
      "source": [
        "# Build dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cfc14f60f4a160e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfc14f60f4a160e6",
        "outputId": "d892d897-e8d6-41f2-f942-ee3c3a7f038d"
      },
      "outputs": [],
      "source": [
        "from dtrocr.processor import DTrOCRProcessor\n",
        "from dtrocr.config import DTrOCRConfig\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IAMDataset(Dataset):\n",
        "    def __init__(self, words: list[Word], config: DTrOCRConfig):\n",
        "        super(IAMDataset, self).__init__()\n",
        "        self.words = words\n",
        "        self.processor = DTrOCRProcessor(config, add_eos_token=True, add_bos_token=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = self.processor(\n",
        "            images=Image.open(self.words[item].file_path).convert('RGB'),\n",
        "            texts=self.words[item].transcription,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\",\n",
        "            return_labels=True,\n",
        "        )\n",
        "        return {\n",
        "            'pixel_values': inputs.pixel_values[0],\n",
        "            'input_ids': inputs.input_ids[0],\n",
        "            'attention_mask': inputs.attention_mask[0],\n",
        "            'labels': inputs.labels[0]\n",
        "        }\n",
        "\n",
        "config = DTrOCRConfig(\n",
        "    #use_rnnt_loss=True\n",
        ")\n",
        "\n",
        "train_data = IAMDataset(words=train_word_records, config=config)\n",
        "validation_data = IAMDataset(words=validation_word_records, config=config)\n",
        "test_data = IAMDataset(words=test_word_records, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3f9717df54449a10",
      "metadata": {
        "id": "3f9717df54449a10"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import multiprocessing as mp\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=mp.cpu_count())\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=32, shuffle=False, num_workers=mp.cpu_count())\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=mp.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c460aa9a2caa3af6",
      "metadata": {
        "id": "c460aa9a2caa3af6"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "18096c11905a980e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18096c11905a980e",
        "outputId": "7d34197b-8e88-4244-cf1e-f22a796fdc31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): DTrOCRLMHeadModel(\n",
              "    (transformer): DTrOCRModel(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(4, 8), stride=(4, 8))\n",
              "      )\n",
              "      (token_embedding): Embedding(50257, 768)\n",
              "      (positional_embedding): Embedding(256, 768)\n",
              "      (hidden_layers): ModuleList(\n",
              "        (0-11): 12 x GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D(nf=2304, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=768)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D(nf=3072, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=3072)\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (language_model_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "from dtrocr.model import DTrOCRLMHeadModel\n",
        "\n",
        "model = DTrOCRLMHeadModel(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a10a9feb1801174",
      "metadata": {
        "id": "2a10a9feb1801174"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "l6bsyFBEeOQh",
      "metadata": {
        "id": "l6bsyFBEeOQh"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch' from 'C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py' has no attribute 'fx' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\n\u001b[32m      2\u001b[39m torch._dynamo.config.suppress_errors = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py:2222\u001b[39m\n\u001b[32m   2218\u001b[39m sys.modules.setdefault(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.classes\u001b[39m\u001b[33m\"\u001b[39m, classes)\n\u001b[32m   2220\u001b[39m \u001b[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001b[39;00m\n\u001b[32m   2221\u001b[39m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2222\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2224\u001b[39m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[32m   2225\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\quantization\\__init__.py:6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquant_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\quantization\\qconfig.py:9\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m \u001b[33;03mhere.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     _add_module_to_qconfig_obs_ctr,\n\u001b[32m     11\u001b[39m     _assert_valid_qconfig,\n\u001b[32m     12\u001b[39m     default_activation_only_qconfig,\n\u001b[32m     13\u001b[39m     default_debug_qconfig,\n\u001b[32m     14\u001b[39m     default_dynamic_qconfig,\n\u001b[32m     15\u001b[39m     default_per_channel_qconfig,\n\u001b[32m     16\u001b[39m     default_qat_qconfig,\n\u001b[32m     17\u001b[39m     default_qat_qconfig_v2,\n\u001b[32m     18\u001b[39m     default_qconfig,\n\u001b[32m     19\u001b[39m     default_weight_only_qconfig,\n\u001b[32m     20\u001b[39m     float16_dynamic_qconfig,\n\u001b[32m     21\u001b[39m     float16_static_qconfig,\n\u001b[32m     22\u001b[39m     float_qparams_weight_only_qconfig,\n\u001b[32m     23\u001b[39m     get_default_qat_qconfig,\n\u001b[32m     24\u001b[39m     get_default_qconfig,\n\u001b[32m     25\u001b[39m     per_channel_dynamic_qconfig,\n\u001b[32m     26\u001b[39m     QConfig,\n\u001b[32m     27\u001b[39m     qconfig_equals,\n\u001b[32m     28\u001b[39m     QConfigAny,\n\u001b[32m     29\u001b[39m     QConfigDynamic,\n\u001b[32m     30\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\ao\\quantization\\__init__.py:12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfuser_method_mappings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mobserver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_numeric_debugger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     13\u001b[39m     compare_results,\n\u001b[32m     14\u001b[39m     CUSTOM_KEY,\n\u001b[32m     15\u001b[39m     extract_results_from_loggers,\n\u001b[32m     16\u001b[39m     generate_numeric_debug_handle,\n\u001b[32m     17\u001b[39m     NUMERIC_DEBUG_HANDLE_KEY,\n\u001b[32m     18\u001b[39m     prepare_for_propagation_comparison,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     _allow_exported_model_train_eval \u001b[38;5;28;01mas\u001b[39;00m allow_exported_model_train_eval,\n\u001b[32m     22\u001b[39m     _move_exported_model_to_eval \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_eval,\n\u001b[32m     23\u001b[39m     _move_exported_model_to_train \u001b[38;5;28;01mas\u001b[39;00m move_exported_model_to_train,\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mqconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\ao\\quantization\\pt2e\\_numeric_debugger.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mns\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compute_sqnr\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mao\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantization\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpt2e\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_control_flow_submodules\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphModule, Node\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\export\\__init__.py:77\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexported_program\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     71\u001b[39m     default_decompositions,\n\u001b[32m     72\u001b[39m     ExportedProgram,\n\u001b[32m     73\u001b[39m     ModuleCallEntry,\n\u001b[32m     74\u001b[39m     ModuleCallSignature,\n\u001b[32m     75\u001b[39m )\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_signature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportBackwardSignature, ExportGraphSignature\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01munflatten\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FlatArgsAdapter, unflatten, UnflattenedModule\n\u001b[32m     80\u001b[39m PassType = Callable[[torch.fx.GraphModule], Optional[PassResult]]\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexport_for_training\u001b[39m(\n\u001b[32m     84\u001b[39m     mod: torch.nn.Module,\n\u001b[32m     85\u001b[39m     args: Tuple[Any, ...],\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m     preserve_module_call_signature: Tuple[\u001b[38;5;28mstr\u001b[39m, ...] = (),\n\u001b[32m     91\u001b[39m ) -> ExportedProgram:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\export\\unflatten.py:34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_attr, _get_attr_via_attr_list, _print_readable\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GetAttrKey, SequenceKey\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_remove_effect_tokens_pass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _remove_effect_tokens\n\u001b[32m     37\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     40\u001b[39m __all__ = [\n\u001b[32m     41\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFlatArgsAdapter\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mInterpreterModule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munflatten\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     46\u001b[39m ]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\export\\_remove_effect_tokens_pass.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meffects\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _get_schema, with_effects\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexported_program\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExportedProgram\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_signature\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     CustomObjArgument,\n\u001b[32m     11\u001b[39m     InputKind,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     TokenArgument,\n\u001b[32m     16\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_higher_order_ops\\effects.py:10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pytree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytree\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DispatchKey\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtorchbind\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m call_torchbind\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HigherOrderOperator\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensorMode\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_higher_order_ops\\torchbind.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DispatchKey  \u001b[38;5;66;03m# @manual\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_aot_autograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNOWN_TYPES\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_higher_order_ops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograd_not_implemented\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_library\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_class_registry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ns_and_class_name, FakeScriptObject\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_functorch\\_aot_autograd\\utils.py:481\u001b[39m\n\u001b[32m    474\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m buffer\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.nn.modules.module.register_module_buffer_registration_hook(\n\u001b[32m    477\u001b[39m         _map_assigned_buffer_to_proxy\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontain_metadata_mutation_ops\u001b[39m(module: \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfx\u001b[49m.GraphModule) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    482\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m    Checks if the module contains any metadata mutation ops.\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m module.graph.nodes:\n",
            "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch' from 'C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py' has no attribute 'fx' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "59bc296d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "12.4\n",
            "0\n",
            "NVIDIA T1200 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print True\n",
        "print(torch.version.cuda)         # Should match your CUDA toolkit\n",
        "print(torch.cuda.current_device()) # Should print 0 (or your GPU index)\n",
        "print(torch.cuda.get_device_name(0)) # Should print \"NVIDIA T1200 Laptop GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ae76c9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Epoch 0, Loss: 1.1223242282867432\n",
            "Epoch 1, Loss: 1.1118525266647339\n",
            "Epoch 2, Loss: 1.1018106937408447\n",
            "Epoch 3, Loss: 1.0921796560287476\n",
            "Epoch 4, Loss: 1.0829410552978516\n",
            "Epoch 5, Loss: 1.0740772485733032\n",
            "Epoch 6, Loss: 1.065571904182434\n",
            "Epoch 7, Loss: 1.0574090480804443\n",
            "Epoch 8, Loss: 1.0495736598968506\n",
            "Epoch 9, Loss: 1.0420513153076172\n",
            "Epoch 10, Loss: 1.0348284244537354\n",
            "Epoch 11, Loss: 1.0278918743133545\n",
            "Epoch 12, Loss: 1.0212290287017822\n",
            "Epoch 13, Loss: 1.0148284435272217\n",
            "Epoch 14, Loss: 1.008678674697876\n",
            "Epoch 15, Loss: 1.002768635749817\n",
            "Epoch 16, Loss: 0.9970884323120117\n",
            "Epoch 17, Loss: 0.991628110408783\n",
            "Epoch 18, Loss: 0.9863782525062561\n",
            "Epoch 19, Loss: 0.9813299179077148\n",
            "Epoch 20, Loss: 0.9764746427536011\n",
            "Epoch 21, Loss: 0.9718043804168701\n",
            "Epoch 22, Loss: 0.9673112034797668\n",
            "Epoch 23, Loss: 0.9629878997802734\n",
            "Epoch 24, Loss: 0.9588271379470825\n",
            "Epoch 25, Loss: 0.9548223614692688\n",
            "Epoch 26, Loss: 0.950967013835907\n",
            "Epoch 27, Loss: 0.94725501537323\n",
            "Epoch 28, Loss: 0.943680465221405\n",
            "Epoch 29, Loss: 0.9402375817298889\n",
            "Epoch 30, Loss: 0.936921238899231\n",
            "Epoch 31, Loss: 0.9337261915206909\n",
            "Epoch 32, Loss: 0.9306475520133972\n",
            "Epoch 33, Loss: 0.9276805520057678\n",
            "Epoch 34, Loss: 0.9248208403587341\n",
            "Epoch 35, Loss: 0.9220638871192932\n",
            "Epoch 36, Loss: 0.9194058775901794\n",
            "Epoch 37, Loss: 0.9168427586555481\n",
            "Epoch 38, Loss: 0.9143707156181335\n",
            "Epoch 39, Loss: 0.911986231803894\n",
            "Epoch 40, Loss: 0.9096858501434326\n",
            "Epoch 41, Loss: 0.9074664115905762\n",
            "Epoch 42, Loss: 0.9053245186805725\n",
            "Epoch 43, Loss: 0.9032573699951172\n",
            "Epoch 44, Loss: 0.9012618660926819\n",
            "Epoch 45, Loss: 0.8993354439735413\n",
            "Epoch 46, Loss: 0.8974754810333252\n",
            "Epoch 47, Loss: 0.895679235458374\n",
            "Epoch 48, Loss: 0.8939444422721863\n",
            "Epoch 49, Loss: 0.892268717288971\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Dummy model and data\n",
        "model = nn.Linear(10, 1).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "data = torch.randn(100, 10).to(device)\n",
        "target = torch.randn(100, 1).to(device)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = nn.MSELoss()(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8257602fcea271d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8257602fcea271d",
        "outputId": "421a977a-ad6b-4071-c856-0768e9958024"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_10816\\1899687729.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
            "Epoch 1:   0%|          | 0/1698 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def evaluate_model(model: torch.nn.Module, dataloader: DataLoader) -> Tuple[float, float]:\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    losses, accuracies = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm.tqdm(dataloader, total=len(dataloader), desc=f'Evaluating test set'):\n",
        "            inputs = send_inputs_to_device(inputs, device='cuda')\n",
        "            outputs = model(**inputs)\n",
        "            \n",
        "            losses.append(outputs.loss.item())\n",
        "            accuracies.append(outputs.accuracy.item())\n",
        "    \n",
        "    loss = sum(losses) / len(losses)\n",
        "    accuracy = sum(accuracies) / len(accuracies)\n",
        "    \n",
        "    # set model back to training mode\n",
        "    model.train()\n",
        "    \n",
        "    return loss, accuracy\n",
        "\n",
        "def send_inputs_to_device(dictionary, device):\n",
        "    return {key: value.to(device=device) if isinstance(value, torch.Tensor) else value for key, value in dictionary.items()}\n",
        "\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "optimiser = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 5\n",
        "train_losses, train_accuracies = [], []\n",
        "validation_losses, validation_accuracies = [], []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_losses, epoch_accuracies = [], []\n",
        "    for inputs in tqdm.tqdm(train_dataloader, total=len(train_dataloader), desc=f'Epoch {epoch + 1}'):\n",
        "        \n",
        "        # set gradients to zero\n",
        "        optimiser.zero_grad()\n",
        "        \n",
        "        # send inputs to same device as model\n",
        "        inputs = send_inputs_to_device(inputs, device=0)\n",
        "        \n",
        "        # forward pass\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        # calculate gradients\n",
        "        scaler.scale(outputs.loss).backward()\n",
        "        \n",
        "        # update weights\n",
        "        scaler.step(optimiser)\n",
        "        scaler.update()\n",
        "        \n",
        "        epoch_losses.append(outputs.loss.item())\n",
        "        epoch_accuracies.append(outputs.accuracy.item())\n",
        "        \n",
        "    # store loss and metrics\n",
        "    train_losses.append(sum(epoch_losses) / len(epoch_losses))\n",
        "    train_accuracies.append(sum(epoch_accuracies) / len(epoch_accuracies))\n",
        "    \n",
        "    # tests loss and accuracy\n",
        "    validation_loss, validation_accuracy = evaluate_model(model, validation_dataloader)\n",
        "    validation_losses.append(validation_loss)\n",
        "    validation_accuracies.append(validation_accuracy)\n",
        "                    \n",
        "    print(f\"Epoch: {epoch + 1} - Train loss: {train_losses[-1]}, Train accuracy: {train_accuracies[-1]}, Validation loss: {validation_losses[-1]}, Validation accuracy: {validation_accuracies[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6399ad87bbfd16da",
      "metadata": {
        "id": "6399ad87bbfd16da"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LJjkq6UmZ5Yi",
      "metadata": {
        "id": "LJjkq6UmZ5Yi"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'full_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51d7fd369dee5ce",
      "metadata": {
        "id": "b51d7fd369dee5ce"
      },
      "outputs": [],
      "source": [
        "from DTrOCR.dtrocr.model import DTrOCRLMHeadModel\n",
        "from DTrOCR.dtrocr.config import DTrOCRConfig\n",
        "from DTrOCR.dtrocr.processor import DTrOCRProcessor\n",
        "\n",
        "# model = DTrOCRLMHeadModel(DTrOCRConfig())\n",
        "model.eval()\n",
        "model.to('cpu')\n",
        "test_processor = DTrOCRProcessor(DTrOCRConfig())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e815a0557072e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "81e815a0557072e4",
        "outputId": "c74671a3-f6f7-4aa4-c7ef-1e491bd0791a"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "for test_word_record in test_word_records[:50]:\n",
        "    image_file = test_word_record.file_path\n",
        "    image = Image.open(image_file).convert('RGB')\n",
        "\n",
        "    inputs = test_processor(\n",
        "        images=image,\n",
        "        texts=test_processor.tokeniser.bos_token,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    model_output = model.generate(\n",
        "        inputs,\n",
        "        test_processor,\n",
        "        num_beams=3\n",
        "    )\n",
        "\n",
        "    predicted_text = test_processor.tokeniser.decode(model_output[0], skip_special_tokens=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(predicted_text, fontsize=24)\n",
        "    plt.imshow(np.array(image, dtype=np.uint8))\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
