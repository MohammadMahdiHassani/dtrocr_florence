{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4cda29000b17cc0a",
      "metadata": {
        "id": "4cda29000b17cc0a"
      },
      "source": [
        "# Fine-tuning DTrOCR on IAM dataset\n",
        "This is an example of fine-tuning DTrOCR on IAM dataset handwritten words from [Kaggle](https://www.kaggle.com/datasets/teykaicong/iamondb-handwriting-dataset). IAM Aachen splits can be downloaded [here](https://www.openslr.org/56/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "672df8f4f58440b7",
      "metadata": {
        "id": "672df8f4f58440b7"
      },
      "source": [
        "# Dataset folder structure\n",
        "```\n",
        "iam_words/\n",
        "│\n",
        "├── words/                              # Folder containing word images as PNGs\n",
        "│   ├── a01/                            # First folder\n",
        "│   │   ├── a01-000u/\n",
        "│   │   │   ├── a01-000u-00-00.png\n",
        "│   │   │   └── a01-000u-00-01.png\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   │   .\n",
        "│   └── r06/                            # Last folder\n",
        "│       ├── r06-000/\n",
        "│       │   ├── r06-000-00-00.png\n",
        "│       │   └── r06-000-00-01.png\n",
        "│\n",
        "├── xml/                                # XML files\n",
        "│\t├── a01-000u.xml\n",
        "│\t.\n",
        "│\t.\n",
        "│\t.\n",
        "│\t└── r06-143.xml\n",
        "│\n",
        "└── splits/                             # IAM Aachen splits\n",
        "    ├── train.uttlist\n",
        "    ├── validation.uttlist\n",
        "    └── test.uttlist\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89f83c2b6af325eb",
      "metadata": {
        "id": "89f83c2b6af325eb"
      },
      "source": [
        "# Build lists of images and texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0Tz0PKVm3hNH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Tz0PKVm3hNH",
        "outputId": "b81c307c-87d6-44ed-9518-65cd874ca8e7"
      },
      "outputs": [],
      "source": [
        "#!pip install triton==2.0.0 # Install Triton explicitly with a version compatible with PyTorch Inductor.\n",
        "\n",
        "import torch\n",
        "torch.set_float32_matmul_precision('high')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa6ad879545d49c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa6ad879545d49c7",
        "outputId": "08a19f21-1da9-4491-a610-269d1257dde5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1539 XML files and 115320 word image files\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_path = Path('iam_words')\n",
        "\n",
        "xml_files = sorted(glob.glob(str(dataset_path / 'xml' / '*.xml')))\n",
        "word_image_files = sorted(glob.glob(str(dataset_path / 'words' / '**' / '*.png'), recursive=True))\n",
        "\n",
        "print(f\"{len(xml_files)} XML files and {len(word_image_files)} word image files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6wC_EzQfhZly",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wC_EzQfhZly",
        "outputId": "32d64c26-9ece-45fa-cb49-0728e5465766"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# Define the Word class\n",
        "class Word:\n",
        "    def __init__(self, word_id, file_path, writer_id, transcription):\n",
        "        self.id:str = word_id\n",
        "        self.file_path:Path = file_path\n",
        "        self.writer_id:str = writer_id\n",
        "        self.transcription:str = transcription\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Word(id='{self.id}', file_path=PosixPath('{self.file_path}'), \"\n",
        "                f\"writer_id='{self.writer_id}', transcription='{self.transcription}')\")\n",
        "pattern = r\"Word\\(id='([^']+)',\\s*file_path=PosixPath\\('([^']+)'\\),\\s*writer_id='([^']+)',\\s*transcription='([^']+)'\\)\"\n",
        "\n",
        "def extract_word_obj(line:str):\n",
        "  match = re.search(pattern, line)\n",
        "\n",
        "# Check if the match was successful\n",
        "  if match:\n",
        "    word_id = match.group(1)\n",
        "    file_path = Path(match.group(2))  # Convert the string to a Path object\n",
        "    writer_id = match.group(3)\n",
        "    transcription = match.group(4)\n",
        "\n",
        "    # Create the Word object\n",
        "    word_object = Word(word_id, file_path, writer_id, transcription)\n",
        "    return word_object\n",
        "words = []\n",
        "# Example: Reading the file and loading each line as a Word object\n",
        "file_path = 'words_local.txt'  # Replace with your file path\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    # Read the lines of the file and convert each to a Word instance\n",
        "    for line in file.readlines():\n",
        "      word = extract_word_obj(line)\n",
        "      words.append(word)\n",
        "# Print the loaded Word instan"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ea1601f0dabbde",
      "metadata": {
        "id": "d0ea1601f0dabbde"
      },
      "source": [
        "# Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c5c924f758cc73a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5c924f758cc73a4",
        "outputId": "64177ffd-a560-45c1-f382-18b8d9030296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 747; Validation size: 116; Test size: 336\n"
          ]
        }
      ],
      "source": [
        "with open('iam_words/splits/train.uttlist') as fp:\n",
        "    train_ids = [line.replace('\\n', '') for line in fp.readlines()]\n",
        "\n",
        "with open('iam_words/splits/test.uttlist') as fp:\n",
        "    test_ids = [line.replace('\\n', '') for line in fp.readlines()]\n",
        "\n",
        "with open('iam_words/splits/validation.uttlist') as fp:\n",
        "    validation_ids = [line.replace('\\n', '') for line in fp.readlines()]\n",
        "\n",
        "print(f\"Train size: {len(train_ids)}; Validation size: {len(validation_ids)}; Test size: {len(test_ids)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ddcnEs96lNkY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddcnEs96lNkY",
        "outputId": "46b18ecd-90ba-4a6f-e693-ec976504481c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "113332\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for word in words:\n",
        "  if words[i] == None:\n",
        "    words.pop(i)\n",
        "  i += 1\n",
        "print(len(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b5433445168c7f98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5433445168c7f98",
        "outputId": "07935b35-426a-44b0-e059-c46b4458bab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 54315; Validation size: 8727; Test size: 25491\n"
          ]
        }
      ],
      "source": [
        "train_word_records = [word for word in words if word.id in train_ids]\n",
        "validation_word_records = [word for word in words if word.id in validation_ids]\n",
        "test_word_records = [word for word in words if word.id in test_ids]\n",
        "\n",
        "print(f'Train size: {len(train_word_records)}; Validation size: {len(validation_word_records)}; Test size: {len(test_word_records)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1d6d01cac2ef35",
      "metadata": {
        "id": "ce1d6d01cac2ef35"
      },
      "source": [
        "# Build dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cfc14f60f4a160e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfc14f60f4a160e6",
        "outputId": "d892d897-e8d6-41f2-f942-ee3c3a7f038d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "935c13701b394c1e937279d6ff8604b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--microsoft--Florence-2-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "516decd883644eb6a08b28b64e625f92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "processing_florence2.py:   0%|          | 0.00/48.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large:\n",
            "- processing_florence2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53e716ef12664dd98fc3f0efdb98aceb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/34.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd211f70c0e240bab9b513f2650e0779",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8f1f0bea8184093967e796d100f1072",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e44ac986d7845038a67971efad614b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/2.44k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35dcc86b35df4193aff2c7ff45cd81e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_florence2.py:   0%|          | 0.00/15.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/microsoft/Florence-2-large:\n",
            "- configuration_florence2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        }
      ],
      "source": [
        "from dtrocr.processor import DTrOCRProcessor\n",
        "from dtrocr.config import DTrOCRConfig\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class IAMDataset(Dataset):\n",
        "    def __init__(self, words: list[Word], config: DTrOCRConfig):\n",
        "        super(IAMDataset, self).__init__()\n",
        "        self.words = words\n",
        "        self.processor = DTrOCRProcessor(config, add_eos_token=True, add_bos_token=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        inputs = self.processor(\n",
        "            images=Image.open(self.words[item].file_path).convert('RGB'),\n",
        "            texts=self.words[item].transcription,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\",\n",
        "            return_labels=True,\n",
        "        )\n",
        "        return {\n",
        "            'pixel_values': inputs.pixel_values[0],\n",
        "            'input_ids': inputs.input_ids[0],\n",
        "            'attention_mask': inputs.attention_mask[0],\n",
        "            'labels': inputs.labels[0]\n",
        "        }\n",
        "\n",
        "config = DTrOCRConfig(\n",
        "    #use_rnnt_loss=True\n",
        ")\n",
        "\n",
        "train_data = IAMDataset(words=train_word_records, config=config)\n",
        "validation_data = IAMDataset(words=validation_word_records, config=config)\n",
        "test_data = IAMDataset(words=test_word_records, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3f9717df54449a10",
      "metadata": {
        "id": "3f9717df54449a10"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import multiprocessing as mp\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "from PIL import Image\n",
        "from dataclasses import dataclass\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=mp.cpu_count())\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=32, shuffle=False, num_workers=mp.cpu_count())\n",
        "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, num_workers=mp.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c460aa9a2caa3af6",
      "metadata": {
        "id": "c460aa9a2caa3af6"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "18096c11905a980e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18096c11905a980e",
        "outputId": "7d34197b-8e88-4244-cf1e-f22a796fdc31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): DTrOCRLMHeadModel(\n",
              "    (transformer): DTrOCRModel(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (token_embedding): Embedding(50257, 768)\n",
              "      (positional_embedding): Embedding(256, 768)\n",
              "      (hidden_layers): ModuleList(\n",
              "        (0-23): 24 x GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D(nf=2304, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=768)\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D(nf=3072, nx=768)\n",
              "            (c_proj): Conv1D(nf=768, nx=3072)\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (language_model_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "from dtrocr.model import DTrOCRLMHeadModel\n",
        "\n",
        "model = DTrOCRLMHeadModel(config)\n",
        "model = torch.compile(model)\n",
        "model.to(device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a10a9feb1801174",
      "metadata": {
        "id": "2a10a9feb1801174"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "l6bsyFBEeOQh",
      "metadata": {
        "id": "l6bsyFBEeOQh"
      },
      "outputs": [],
      "source": [
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "59bc296d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "12.4\n",
            "0\n",
            "NVIDIA T1200 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print True\n",
        "print(torch.version.cuda)         # Should match your CUDA toolkit\n",
        "print(torch.cuda.current_device()) # Should print 0 (or your GPU index)\n",
        "print(torch.cuda.get_device_name(0)) # Should print \"NVIDIA T1200 Laptop GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8257602fcea271d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8257602fcea271d",
        "outputId": "421a977a-ad6b-4071-c856-0768e9958024"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_16772\\1208309314.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
            "Epoch 1:   0%|          | 0/1698 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def evaluate_model(model: torch.nn.Module, dataloader: DataLoader) -> Tuple[float, float]:\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    losses, accuracies = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs in tqdm.tqdm(dataloader, total=len(dataloader), desc=f'Evaluating test set'):\n",
        "            inputs = send_inputs_to_device(inputs, device=0)\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            losses.append(outputs.loss.item())\n",
        "            accuracies.append(outputs.accuracy.item())\n",
        "\n",
        "    loss = sum(losses) / len(losses)\n",
        "    accuracy = sum(accuracies) / len(accuracies)\n",
        "\n",
        "    # set model back to training mode\n",
        "    model.train()\n",
        "\n",
        "    return loss, accuracy\n",
        "\n",
        "def send_inputs_to_device(dictionary, device):\n",
        "    return {key: value.to(device=device) if isinstance(value, torch.Tensor) else value for key, value in dictionary.items()}\n",
        "\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "optimiser = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 8\n",
        "train_losses, train_accuracies = [], []\n",
        "validation_losses, validation_accuracies = [], []\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_losses, epoch_accuracies = [], []\n",
        "    for inputs in tqdm.tqdm(train_dataloader, total=len(train_dataloader), desc=f'Epoch {epoch + 1}'):\n",
        "\n",
        "        # set gradients to zero\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        # send inputs to same device as model\n",
        "        inputs = send_inputs_to_device(inputs, device=0)\n",
        "\n",
        "        # forward pass\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=use_amp):\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # calculate gradients\n",
        "        scaler.scale(outputs.loss).backward()\n",
        "\n",
        "        # update weights\n",
        "        scaler.step(optimiser)\n",
        "        scaler.update()\n",
        "\n",
        "        epoch_losses.append(outputs.loss.item())\n",
        "        epoch_accuracies.append(outputs.accuracy.item())\n",
        "\n",
        "    # store loss and metrics\n",
        "    train_losses.append(sum(epoch_losses) / len(epoch_losses))\n",
        "    train_accuracies.append(sum(epoch_accuracies) / len(epoch_accuracies))\n",
        "\n",
        "    # tests loss and accuracy\n",
        "    validation_loss, validation_accuracy = evaluate_model(model, validation_dataloader)\n",
        "    validation_losses.append(validation_loss)\n",
        "    validation_accuracies.append(validation_accuracy)\n",
        "\n",
        "    print(f\"Epoch: {epoch + 1} - Train loss: {train_losses[-1]}, Train accuracy: {train_accuracies[-1]}, Validation loss: {validation_losses[-1]}, Validation accuracy: {validation_accuracies[-1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6399ad87bbfd16da",
      "metadata": {
        "id": "6399ad87bbfd16da"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LJjkq6UmZ5Yi",
      "metadata": {
        "id": "LJjkq6UmZ5Yi"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'full_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51d7fd369dee5ce",
      "metadata": {
        "id": "b51d7fd369dee5ce"
      },
      "outputs": [],
      "source": [
        "from DTrOCR.dtrocr.model import DTrOCRLMHeadModel\n",
        "from DTrOCR.dtrocr.config import DTrOCRConfig\n",
        "from DTrOCR.dtrocr.processor import DTrOCRProcessor\n",
        "\n",
        "# model = DTrOCRLMHeadModel(DTrOCRConfig())\n",
        "model.eval()\n",
        "model.to('cpu')\n",
        "test_processor = DTrOCRProcessor(DTrOCRConfig())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e815a0557072e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "81e815a0557072e4",
        "outputId": "c74671a3-f6f7-4aa4-c7ef-1e491bd0791a"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "for test_word_record in test_word_records[:50]:\n",
        "    image_file = test_word_record.file_path\n",
        "    image = Image.open(image_file).convert('RGB')\n",
        "\n",
        "    inputs = test_processor(\n",
        "        images=image,\n",
        "        texts=test_processor.tokeniser.bos_token,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    model_output = model.generate(\n",
        "        inputs,\n",
        "        test_processor,\n",
        "        num_beams=3\n",
        "    )\n",
        "\n",
        "    predicted_text = test_processor.tokeniser.decode(model_output[0], skip_special_tokens=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.title(predicted_text, fontsize=24)\n",
        "    plt.imshow(np.array(image, dtype=np.uint8))\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
